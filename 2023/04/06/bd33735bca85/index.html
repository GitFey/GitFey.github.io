<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>轨迹预测之实验设置 | 罗辑往事</title><meta name="author" content="罗辑往事"><meta name="copyright" content="罗辑往事"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="数据集对于行人轨迹预测，常用的数据集为ETH [1]和UCY[2] 。这两个数据集是包含了大量的社会交互，这两个数据集中加起来共有1536名行人，上千条真实轨迹，包含行人绕开障碍物、单个行人与人群的相向而行、路口行人转弯等多种真实场景。是行人轨迹预测常用的基准数据集。其中，又分别包含了5个人群数据集。  EHT : 包含 ETH-univ, ETH-hotel UCY : 包含 UCY-zara0">
<meta property="og:type" content="article">
<meta property="og:title" content="轨迹预测之实验设置">
<meta property="og:url" content="http://pfzone.top/2023/04/06/bd33735bca85/index.html">
<meta property="og:site_name" content="罗辑往事">
<meta property="og:description" content="数据集对于行人轨迹预测，常用的数据集为ETH [1]和UCY[2] 。这两个数据集是包含了大量的社会交互，这两个数据集中加起来共有1536名行人，上千条真实轨迹，包含行人绕开障碍物、单个行人与人群的相向而行、路口行人转弯等多种真实场景。是行人轨迹预测常用的基准数据集。其中，又分别包含了5个人群数据集。  EHT : 包含 ETH-univ, ETH-hotel UCY : 包含 UCY-zara0">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://pfzone.top/img/cover/exp.png">
<meta property="article:published_time" content="2023-04-06T02:00:00.000Z">
<meta property="article:modified_time" content="2023-04-25T08:40:46.323Z">
<meta property="article:author" content="罗辑往事">
<meta property="article:tag" content="轨迹预测">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://pfzone.top/img/cover/exp.png"><link rel="shortcut icon" href="/img/christmasjuju.png"><link rel="canonical" href="http://pfzone.top/2023/04/06/bd33735bca85/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '轨迹预测之实验设置',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-04-25 16:40:46'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><script src="https://cyan-blog.oss-cn-shenzhen.aliyuncs.com/cdn/js/three.min.js"></script><link rel="stylesheet" href="/css/myfont.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="loading-box"><div class="centered"><div class="blob-1"></div><div class="blob-2"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
//监听页面加载完毕，因为页面加载速度太快，动画太短，禁用此项
window.addEventListener('load',()=> { preloader.endLoading() })  

//2秒自动关闭加载动画
setTimeout(function(){preloader.endLoading();}, 2000);

//鼠标点击事件关闭加载动画，狍狍等不及可以点一下
document.getElementById('loading-box').addEventListener('click',()=> {preloader.endLoading()}) 



if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/christmasjuju.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">60</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gallery"><span> 相册</span></a></div></div></div></div><div class="canvas-container" id="canvas"></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/cover/exp.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">罗辑往事</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/gallery"><span> 相册</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">轨迹预测之实验设置</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-04-06T02:00:00.000Z" title="发表于 2023-04-06 10:00:00">2023-04-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-04-25T08:40:46.323Z" title="更新于 2023-04-25 16:40:46">2023-04-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="轨迹预测之实验设置"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>对于行人轨迹预测，常用的数据集为ETH [1]和UCY[2] 。这两个数据集是包含了大量的社会交互，这两个数据集中加起来共有1536名行人，上千条真实轨迹，包含行人绕开障碍物、单个行人与人群的相向而行、路口行人转弯等多种真实场景。是行人轨迹预测常用的基准数据集。其中，又分别包含了5个人群数据集。</p>
<ul>
<li>EHT : 包含 ETH-univ, ETH-hotel</li>
<li>UCY : 包含 UCY-zara01, UCY-zara02 and UCY-univ.</li>
</ul>
<p>这两个数据集以每秒2.5帧的速度标记真实位置，在实验中采用观察过去8帧（3.2秒）来预测未来12帧(4.8秒)的形式进行训练与测试。</p>
<p> [1]S. Pellegrini, A. Ess, K. Schindler, and L. J. Van Gool. You’ll never walk alone: Modeling social behavior for multi-target tracking. In ICCV, volume 9, pages 261–268, 2009.</p>
<p>[2] A. Lerner, Y. Chrysanthou, and D. Lischinski. Crowds by example. In Computer Graphics Forum, volume 26, pages 655–664. Wiley Online Library, 2007.</p>
<h2 id="评价方法"><a href="#评价方法" class="headerlink" title="评价方法"></a>评价方法</h2><p>常用的评价方法是 MAD 和 FAD , 出于安全的考虑，还提出了COL（Collision rate）碰撞率 .</p>
<ul>
<li><p>MAD  :  在最后一个时间步长中，预测输出与真实值之间的欧氏距离。</p>
<p><img src="/./img/posts/DP/1.png"></p>
</li>
<li><p>FAD :  所有预测时间步长的地面真实值与预测点之间的平均欧氏距离。</p>
<p><img src="/./img/posts/DP/2.png"></p>
</li>
<li><p>COL : 行人之间的预测轨迹之间发生碰撞的百分比.</p>
<p><img src="/./img/posts/DP/3.png"></p>
</li>
</ul>
<h2 id="参数设置-amp-实施细节"><a href="#参数设置-amp-实施细节" class="headerlink" title="参数设置&amp;实施细节"></a>参数设置&amp;实施细节</h2><h3 id="Social-LSTM"><a href="#Social-LSTM" class="headerlink" title="Social-LSTM"></a>Social-LSTM</h3><blockquote>
<p>We use an embedding dimension of 64 for the spatial coordinates before using them as input to the LSTM. We set the spatial pooling size No to be 32 and use a 8x8 sum pooling window size without overlaps. We used a fifixed hidden state dimension of 128 for all the LSTM models. Additionally, we also use an embedding layer with ReLU (recti-fified Linear Units) non-linearity on top of the pooled hidden state features, before using them for calculating the hidden state tensor Ht i . The hyper-parameters were chosen based on cross-validation on a synthetic dataset. This synthetic was generated using a simulation that implemented the social forces model. This synthetic data contained trajectories for hundreds of scenes with an average crowd density of 30 per frame. We used a learning rate of 0.003 and RMS-prop [14] for training the model. The Social-LSTM model was trained on a single GPU with a Theano [5] implementation.</p>
</blockquote>
<p>空间坐标系 : 64维度的嵌入向量 .</p>
<p>LSTM设置 : 均为 128个隐藏状态.</p>
<p>超参数选择 : 基于数据集上的交叉验证,.</p>
<p>训练 : 使用 RMS-pro,学习率为0.003</p>
<h3 id="SR-LSTM"><a href="#SR-LSTM" class="headerlink" title="SR-LSTM"></a>SR-LSTM</h3><blockquote>
<p>We use single layer MLP to embed the input vectors to32 dimensions, and set the dimension of LSTM hidden state as 64. A sliding time window with a length of 20 and a stride size of 1 is used to get the training samples. All trajectory segments in the same time window are regarded as a mini-batch, as they are processed in parallel. We set the size of mini-batch to 8 during the training stage. We use the single-step mode for training (Fig. 4 (a)), and multi-step mode for validating and testing (Fig. 4 (b)). Adam optimizer is adopted to train models in 300 epochs, with an initial learning rate of 0.001. For training the model with multiple states refifinement layers, we fifixed all basic parameters and only learn the parameters of the additional refifinement layer.</p>
</blockquote>
<p>将输入向量通过单层MLP嵌入到32维</p>
<p>LSTM设置 : 均为 64个隐藏状态.</p>
<p>训练集与测试集设置 : 使用一个长度为20、步幅为1的滑动时间窗来获得训练样本。在同一时间窗内的所有轨迹段都被视为一个小批，因为它们是并行处理的(每一小批设置为8个)。</p>
<p>训练 : 使用Adam优化器 ,学习率为0.001</p>
<h3 id="SoPhie"><a href="#SoPhie" class="headerlink" title="SoPhie"></a>SoPhie</h3><blockquote>
<p>We iteratively trained the generator and discriminator models with the Adam optimizer,using a mini-batch size of 64 and a learning rate of 0.001 for both the generator and the discriminator. Models were trained for 200 epochs. The encoder encodes trajectories using a single layer MLP with an embedding dimension of 16.In the generator this is fed into a LSTM with a hidden dimension of 32; in the discriminator, the same occurs but with a dimension of 64. The decoder of the generator uses a single layer MLP with an embedding dimension of 16 to encoder agent positions and uses a LSTM with a hidden dimension of 32. In the social attention module, attention weights are retrieved by passing the encoder output and decoder context through multiple MLP layers of sizes 64, 128, 64, and 1, with interspersed ReLu activations. The fifinal layer is passed through a Softmax layer. The interactions of the surrounding Nmax &#x3D; 32 agents are considered; this value was chosen as no scenes in either dataset exceeded this number of total active agents in any given timestep. If there are less than Nmax agents, the dummy value of 0 is used. The physical attention module takes raw VGG features (512 channels), projects those using a convolutional layer, and embeds those using a single MLP to an embedding dimension of 16. The discriminator does not use the attention modules or the decoder network. When training we assume we have observed eight timesteps of an agent and are attempting to predict the next T &#x3D; 12 timesteps. We weight our loss function by setting λ &#x3D; 1. Moreover, the generator&#x2F;discriminator are trained jointly in a traditional GAN setting.</p>
</blockquote>
<p>训练 :  使用Adam优化器训练生成器和鉴别器  ,学习率为0.001 .生成器和鉴别器的mini-batch size 均为 64 </p>
<h3 id="Social-GAN"><a href="#Social-GAN" class="headerlink" title="Social-GAN"></a>Social-GAN</h3><blockquote>
<p>We use LSTM as the RNN in our model for both decoder and encoder. The dimensions of the hidden state for encoder is 16 and decoder is 32. We embed the input coordinates as 16 dimensional vectors. We iteratively train the Generator and Discriminator with a batch size of 64 for 200 epochs using Adam [22] with an initial learning rate of 0.001.</p>
</blockquote>
<p>编码器 : 隐藏状态为16的LSTM作为RNN</p>
<p>解码器 : 隐藏状态为32的LSTM作为RNN</p>
<p>训练 ; Adam 迭代训练生成器和鉴别器,batch size为 64,  200个epochs，初始学习率为0.001</p>
<h3 id="SHENet"><a href="#SHENet" class="headerlink" title="SHENet"></a>SHENet</h3><blockquote>
<p>In SHENet, the initial size of group trajectory bank is set to <em>|Z*<em>bank</em></em>|* &#x3D; 32. Both the trajectory encoder and the scene encoder have 4 self-attention (SA) layers. The cross-modal transformer is with 6 SA layers and cross-attention (CA) layers. We set all the embed dimensions to 512. For the trajectory encoder, it learns the human motion information with size of <em>T**pas</em> <em>×</em> 512 (<em>T**pas</em> &#x3D; 8 in ETH&#x2F;UCY, <em>T**pas</em> &#x3D; 10 in PAV). For the scene encoder, it outputs the semantic features with size 150 <em>×</em> 56 <em>×</em> 56. We reshape the features from size 150 <em>×</em> 56 <em>×</em> 56 to 150 <em>×</em> 3136, and project them from dimension 150 <em>×</em> 3136 to 150 <em>×</em> 512. We train the model for 100 epochs on 4 NVIDIA Quadro RTX 6000 GPUs and use the Adam optimizer with a fixed learning rate 1<em>e</em> <em>−</em> 5. More details are in the supplementary material.</p>
</blockquote>
<h3 id="STAR"><a href="#STAR" class="headerlink" title="STAR"></a>STAR</h3><blockquote>
<p>Coordinates as input would be fifirst encoded into a vector in size of 32 by a fully connected layer followed with ReLU activation. The dropout ratio at 0.1 is applied when processing the input data. All the transformer layers accept input with feature size at 32. Both spatial transformer and temporal transformer consists of encoding layers with 8 heads. We performed a hyper-parameter search over the learning rate, from 0.0001 to 0.004 with interval 0.0001 on a smaller network and choose the best-performed learning rate (0.0015) to train all the other models. As a result, we train the network using Adam optimizer with a learning rate of 0.0015 and batch size 16 for 300 epochs. Each batch contains around 256 pedestrians in difffferent time windows indicated by an attention mask to accelerate the training and inference process.</p>
</blockquote>
<p>输入 : 坐标 ,经过一个全连接层  ,编码为32维的向量 .</p>
<p>dropout ratio率 : 0.1</p>
<p>transformer : 输入为32维的向量, 多头注意力机制的头(时间\空间)均设置为8个</p>
<p>训练 : Adam，学习率为0.0015，batch size为16，共300个epochs。</p>
<h3 id="SGCN"><a href="#SGCN" class="headerlink" title="SGCN"></a>SGCN</h3><blockquote>
<p>In our experiments, the embedding dimension of self-attention and the dimension of graph embedding are both set to 64. The number of self-attentionlayer is 1. The asymmetric convolution network comprises 7 convolution layers with kernel size S &#x3D; 3. The spatial temporal GCN and temporal-spatial GCN cascade 1 layer, respectively. And the TCN cascade 4 layers. The thresh old value ξ is empirically set to 0.5. PRelu [13] is adopted as the nonlinear activation δ(·). The proposed method is trained using the Adam [21] optimizer for 150 epochs with data batches of size 128. The initial learning rate is set to 0.001, which is decayed by a factor 0.1 with an interval of 50 epochs. During the inference phase, 20 samples are drawn from the learned bi-variate Gaussian distribution and the closest sample to ground-truth is used to compute the ADE and FDE metrics. Our method is implemented on PyTorch [33]. The code has been published† .</p>
</blockquote>
<p>自注意力嵌入维数 和 图嵌入维数 : 64</p>
<p>非对称卷积网络 : 7个核大小为3的卷积层组成</p>
<p>训练 : 初始学习率设置为0.001，在50个epoch的间隔内衰减了0.1倍。</p>
<p>测试 : 从学习到的双变量高斯分布中抽取20个样本，并使用最接近地面真实值的样本来计算ADE和FDE度量</p>
<h3 id="SNCE"><a href="#SNCE" class="headerlink" title="SNCE"></a>SNCE</h3><blockquote>
<p>In our experiments, we use two different 2-layer MLPs as the projection head <em>ψ</em>(<em>·</em>) and the event encoder <em>ϕ</em>(<em>·</em>). We encode the history observations and future events into 8-dimensional embedding vectors. The distance hyper parameter <em>ρ</em> is set as 0.2 [m] for trajectory forecasting tasks and 0.6 [m] for robot navigation according to the geomet ric size of agents in environments. By default, the sampling horizon <em>δt</em> is set up to 4 and the temperature <em>τ</em> is set as 0.1. All models are trained with the Adam optimizer</p>
</blockquote>
<p>距离超参数 : 0.2m</p>
<p>对比学习 : 采样水平δt设置为4，温度τ设置为0.1</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://pfzone.top">罗辑往事</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://pfzone.top/2023/04/06/bd33735bca85/">http://pfzone.top/2023/04/06/bd33735bca85/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://pfzone.top" target="_blank">罗辑往事</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%BD%A8%E8%BF%B9%E9%A2%84%E6%B5%8B/">轨迹预测</a></div><div class="post_share"><div class="social-share" data-image="/img/cover/exp.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/04/09/ed2c1e885a36/"><img class="prev-cover" src="/img/plant2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MySQL基础架构</div></div></a></div><div class="next-post pull-right"><a href="/2023/04/05/f46e508e303f/"><img class="next-cover" src="/img/guangnian2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java关于继承</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/christmasjuju.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">罗辑往事</div><div class="author-info__description">没有人能找到这里，除了你</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">60</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/GitFey/GitFey.github.io"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎狍狍来访 ！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%96%B9%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">评价方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE-amp-%E5%AE%9E%E6%96%BD%E7%BB%86%E8%8A%82"><span class="toc-number">3.</span> <span class="toc-text">参数设置&amp;实施细节</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Social-LSTM"><span class="toc-number">3.1.</span> <span class="toc-text">Social-LSTM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SR-LSTM"><span class="toc-number">3.2.</span> <span class="toc-text">SR-LSTM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SoPhie"><span class="toc-number">3.3.</span> <span class="toc-text">SoPhie</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Social-GAN"><span class="toc-number">3.4.</span> <span class="toc-text">Social-GAN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SHENet"><span class="toc-number">3.5.</span> <span class="toc-text">SHENet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#STAR"><span class="toc-number">3.6.</span> <span class="toc-text">STAR</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SGCN"><span class="toc-number">3.7.</span> <span class="toc-text">SGCN</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SNCE"><span class="toc-number">3.8.</span> <span class="toc-text">SNCE</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By 罗辑往事</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="/js/sky.js"></script><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>